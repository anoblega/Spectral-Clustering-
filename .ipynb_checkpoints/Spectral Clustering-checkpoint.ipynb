{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# Spectral Clustering\n",
    "\n",
    "\n",
    "## 1. Grafo de Similitud\n",
    "\n",
    "Dados:\n",
    "\n",
    "* Un conjunto de datos $X = \\{x_1, x_2,...,x_n\\}$ \n",
    "\n",
    "* Un valor de similitud $s_{ij} \\geq 0$ entre dos datos $x_i$ y $x_j$. \n",
    "\n",
    "El objetivo es dividir el conjunto $X$ en diferentes grupos, de tal manera que los datos que se encuentran en un mismo grupo son aquellos que son similares entre sí, y diferentes a los que se encuentran en otros grupos. \n",
    "\n",
    "Una manera de representar los *data points* conociendo las *similitudes* entre ellos, es usando una *Matriz de Similitud G = (V,E)*, donde:\n",
    "\n",
    "* Cada vértice $v_i$ representa a un dato $x_i$.\n",
    "\n",
    "* Los vértices $v_i$ y $v_j$ están conectados si su similitud $s_{ij}$ es positiva o mayor a un *threshold*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Notación del Grafo\n",
    "Dado $G = (V, E)$ un grado no-dirigido con el conjunto de vértices $V = \\{v_1, v_2, ..., v_n\\}$.  Asumimos que:\n",
    "\n",
    "\n",
    "![alternate text](pictures/grafo.png)\n",
    "\n",
    "* El grafo $G$ es ponderado, es decir, cada arista entre dos vértices $v_i$ y $v_j$  tiene un peso no-negativo $w_{ij} \\geq 0 $.\n",
    "\n",
    "* La **matriz de adyacencia ponderada**  del grafo es la matriz $W = (w_{ij})_{ij=1,...,n}$ .\n",
    "\n",
    "* Si los vértices $v_i$ y $v_j$ no están conectados entonces $w_{ij} = 0$.\n",
    "\n",
    "* La matriz de adyacencia es *simétrica* pues $w_{ij} = w_{ji}$. \n",
    "\n",
    "* El **grado** de un vértice $v_i$ se define como $$d_i = \\sum_{j = 1}^{n}{w_{ij}}$$ \n",
    "\n",
    "* La **Matriz de Grado D** está definida como la matriz diagonal  con los grados $d_1, d_2,...,d_n$ en la diagonal. \n",
    "\n",
    "![alternate text](pictures/matriz.png)\n",
    "\n",
    "Sea el subconjunto $A \\subset V$ de un **grafo es conexo** si para cualquier par de vértices en $A$ tiene una trayectoria con vértices intermediarios que pertenecen también a $A$.\n",
    "\n",
    "El subconjunto $A$ es llamada **componente conexa** si además de conexo, no hay conexión entre los vértices de $A$ y su complemento $\\bar{A}$.\n",
    "\n",
    "Conociendo lo anterior, podemos definir los conjuntos no vacíos $A_1, A_2, ..., A_k$ son particiones del grafo $A$, tal que:\n",
    "\n",
    "* $A_i \\cap A_j = \\emptyset$\n",
    "* $A_1 \\cup A_2 \\cup ... \\cup A_k = V$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Ejemplos Grafos de Similitud\n",
    "\n",
    "Para transformar un conjunto de *data points* $x_1, x_2, ..., x_n$ en un grafo de similitudes $s_{ij}$ o de distancias $d_{ij}$, existen diversos métodos.\n",
    "\n",
    "Construir *grafos de similitud* ayuda a modelar las relaciones de vecindad local entre los *data points*.\n",
    "\n",
    "* **El Grafo $\\varepsilon-$Neighborhood:**\n",
    "Se conectan aquellos pares de vértices cuya distancia sea más pequeña que $\\varepsilon$. Es así que los pesos del grafo estan en la misma escala.\n",
    "\n",
    "* **El Grafo $k-$Nearest Neighbor**: Los véstices $v_i$ y $v_j$ están conectados si $v_j$ pertenece a los $k$ vecinos más cercanos de $v_i$. Esto define un grafo dirigido, pero ello puede ser solucionado de dos maneras:\n",
    "    * Ignorar las direcciones de los arcos, es decir, existe la arista $e_{ij} \\in E$ tal que $v_i$ es un $k$-vecino más cercano de $v_j$ o viceversa. De ello se obtiene el **grado de k-vecinos más cercanos**\n",
    "    \n",
    "    * Conectar los vértices $v_i$ y $v_j$ si uno pertenece a los $k-$vecinos más cercanos del otro y viceversa, obteniendo el **grafo de k-vecinos más cercanos mutuo**\n",
    "\n",
    "\n",
    "* **El Grafo Completamente Conectado:** Se conectan aquellos vértices cuya similitud es positiva siendo ello su peso de la arista que los une $s_{ij}$. La función a usar debe reflejar las relaciones de vecindad local. \n",
    "\n",
    "    * Un ejemplo de esta función es la **función de similitud Gausiana** $s(x_i, x_j) = \\exp{(-\\frac{\\|x_i - x_j \\|^2}{2\\sigma^2})}$\n",
    "    * $\\sigma$ controla el tamaño de la vecindad  similar a $\\varepsilon$ del grafo  $\\varepsilon-$neigborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Grafos Laplacianos\n",
    "\n",
    "Las principales herramientas para Spectral Clustering son las *matrices de grafos Laplacianos*.\n",
    "\n",
    "Asumiendo que $G$ es un grado no dirigido y ponderado cuya matriz de adyacencia esta dada por $W$ donde $w_{ij} = w_{ji} \\geq 0$.\n",
    "\n",
    "\n",
    "### 2.1 Grafo Laplaciano No-normalizado\n",
    "La matriz del Grafo Laplaciano no-normalizada se define:\n",
    "\n",
    "$$L = D - A$$\n",
    "\n",
    "Esta satisface las siguientes propiedades:\n",
    "\n",
    "* Para cada vector $f$ en $\\Re^2$ se tiene $$f L f' = \\frac{1}{2} \\sum_{i,j=1}^{n}{w_{ij}(f_i-f_j)^2}$$\n",
    "* L es simétrica y semi-definida positiva.\n",
    "* El eigenvalor más pequeño de $L$ es $0$.\n",
    "* $L$ tiene n no-negativos y reales eugenvalores $0 = \\lambda_1 \\leq \\lambda_2 \\leq ... \\leq \\lambda_n$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de Componentes Conexas y Spectrum de L\n",
    "\n",
    "Dado un grafo no dirigido $G$ con pesos no negativos.\n",
    "\n",
    "* La multiplicidad de $k$ del eigenvalor $0$ de $L$, es igual al número de componentes conexas $A_1, A_2, ...,A_k$ del grafo. \n",
    "\n",
    "\n",
    "###### Ejemplo:\n",
    "En el caso de $k = 1$, lo cual indica que el grafo es conexo. Entonces asumimos que $f$ es un eigenvalor con un eigenvalor igual a $0$.\n",
    "$$ 0 = f L f' = \\frac{1}{2} \\sum_{i,j=1}^{n}{w_{ij}(f_i-f_j)^2}$$\n",
    "\n",
    "* Dos vértices estan conectados si $w_{ij} >  0$.\n",
    "* La ecuación anterior se cumple si $f_i - f_j = 0 $, es decir, ambos sean iguales. Por ende, el $f$ tiene que ser constante en todo el componente conexo. Entonces se tiene un sólo eigenvector con su eigenvalor igual a $0$.\n",
    "\n",
    "\n",
    "\n",
    "Ahora consederemos que se tiene $k-componentes$ conexas, de forma mas general asumamos que los vértices estan ordenados y agrupados de acuerdo a sus componentes conexas. En este caso la matriz $W$ queda dividida como sigue:\n",
    " $$L = \\begin{pmatrix}\n",
    "L_1 & &  &  \\\\\n",
    " & L_2 &  &  \\\\\n",
    "&  & \\ddots & \\\\\n",
    "&  &  & L_k \\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "Cada bloque $L_i$ es de por si también un grafo Laplaciano, por lo cual es el Laplaciano correspondiente al $i-esimo$ componente conexo de $L$.\n",
    "\n",
    "En conclusión el Spectrum de $L$ esta dado por la unión de los espectros $L_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Grafo Laplaciano Normalizado\n",
    "\n",
    "La Matriz Laplaciana puede ser definida por:\n",
    "$$L_{norm(i,j)} = \n",
    "\\begin{cases}\n",
    "1 & \\text{, si $i = j$ y $d_i$ $\\neq$ 0}\\\\\n",
    "-\\frac{1}{\\sqrt{d_i *d_j}} & \\text{, si  $i \\neq j$ y $v_i$ es adyacente a $v_j$}\\\\\n",
    "0 & \\text{, otro caso.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "La matriz Laplaciana Normalizada $L_{norm}$ y la matriz Laplaciana $L$ están relacionadas como sigue:\n",
    "\n",
    "$$L_{norm} := D^{-1/2}LD^{-1/2}$$\n",
    "\n",
    "Esta matriz satisface las siguientes propiedades:\n",
    "\n",
    "* Para cada vector $f$ en $\\Re^2$ se tiene $$f L_{norm} f' = \\frac{1}{2} \\sum_{i,j=1}^{n}{w_{ij}(\\frac{f_i}{\\sqrt{d_i}} -\\frac{f_j}{\\sqrt{d_j}})^2}$$\n",
    "* L es simétrica y semi-definida positiva.\n",
    "* El eigenvalor más pequeño de $L$ es $0$.\n",
    "* $L_{norm}$ tiene n no-negativos y reales eugenvalores $0 = \\lambda_1 \\leq \\lambda_2 \\leq ... \\leq \\lambda_n$ \n",
    "\n",
    "Tanto en la matriz $L$ como en la matriz $L_{norm}$, la multiplicidad $k$ del eigenvalor $0$ indican el número de componente conexas $A_i, A_2,...,A_k$ del grafo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algoritmos de Spectral Clustering\n",
    "\n",
    "* Asumimos que nuestros datos son $n$ \"puntos\" $x_1, x_2,...,x_n$ los cuales pueden ser arbitrariamente objetos.\n",
    "* Se cuenta con un valor de similitud entre cada par $s_{ij} = s(x_i, x_j)$ mediante una función de similitus que sea  simétrica y no negativa. Como resultado se obtiene la *Matriz de Similitud* $S=(s_{ij})_{i,j=1,...,n}$\n",
    "\n",
    "### 3.1 Spectral Clustering No-Normalizado\n",
    "Dado una matriz $S \\in \\Re^{nxn}$ y un número $k$ con clusters a construir:\n",
    "\n",
    "* Construimos un *Grafo de Similitud* contenida en la matriz de adyacencia ponderada $W$,  mediante los métodos mencionados anteriormente.\n",
    "* Cálculo de la matriz Laplaciana no normalizada $L$ de W.\n",
    "* Cálculo de los primero $k$ eigenvectores $u_1, u_2,...,u_k$ de $L$.\n",
    "* Dado $U \\in \\Re^{nxk}$, una matriz que contiene todos los eigenvectores como columnas.\n",
    "* Sea $y_{i=1,...,n} \\in \\Re^k$, un vector pertenceciente a $U$. Agrupar los puntos $y_i$ con el algoritmo **k-means** dentro de $C_1,...,C_k$ grupos.\n",
    "    \n",
    "Obtenemos los grupos $A_1,...,A_k$ con $A_i = \\{j | y_j \\in C_i\\}$\n",
    "\n",
    "### 3.2 Spectral Clustering Normalizado\n",
    "\n",
    "Dado una matriz $S \\in \\Re^{nxn}$ y un número $k$ con clusters a construir:\n",
    "\n",
    "* Construimos un *Grafo de Similitud* contenida en la matriz de adyacencia ponderada $W$,  mediante los métodos mencionados anteriormente.\n",
    "* Cálculo de la matriz Laplaciana  normalizada $L_{norm}$ de W.\n",
    "* Cálculo de los primero $k$ eigenvectores $u_1, u_2,...,u_k$ de $L_{norm}$.\n",
    "* Dado $U \\in \\Re^{nxk}$, una matriz que contiene todos los eigenvectores como columnas.\n",
    "* Obtenemos la Matriz $T \\in \\Re^{nxk}$ basada en  la normalización de $U$.\n",
    "$$t_{ij} = \\frac{u_{ij}}{\\sqrt{\\sum_{k}{u_{ik}^2}}}$$\n",
    "* Sea $y_{i=1,...,n} \\in \\Re^k$, un vector pertenceciente a $T$. Agrupar los puntos $y_i$ con el algoritmo **k-means** dentro de $C_1,...,C_k$ grupos.\n",
    "    \n",
    "Obtenemos los grupos $A_1,...,A_k$ con $A_i = \\{j | y_j \\in C_i\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pruebas\n",
    "\n",
    "Para las pruebas se usara datos en 2D, donde mostraremos la eficiencia de agrupamiento de Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generando datos de manera automatica, defidiendo antes el numero de puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 750\n",
    "noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5, noise=.05)\n",
    "noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "\n",
    "colors = np.array([x for x in 'bgrcmykbgrcmykbgrcmykbgrcmyk'])\n",
    "colors = np.hstack([colors] * 20)\n",
    "\n",
    "pl.figure(figsize=(14, 9.5))\n",
    "pl.subplots_adjust(left=.001, right=.999, bottom=.001, top=.96, wspace=.05, hspace=.01)\n",
    "\n",
    "plot_num = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [noisy_circles, noisy_moons, blobs, no_structure]\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "    X, y = dataset\n",
    "    # Normalizando datos para una facil seleccion de parametros\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    # plot\n",
    "    pl.subplot(2, 2, plot_num)\n",
    "    pl.scatter(X[:, 0], X[:, 1], color='g', s=10)\n",
    "\n",
    "    pl.xlim(-2.5, 2.5)\n",
    "    pl.ylim(-2.5, 2.5)\n",
    "    pl.xticks(())\n",
    "    pl.yticks(())\n",
    "    plot_num += 1\n",
    "\n",
    "#pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para una mejor vision del funcionamiento de Spectral Clustering se hara una comparacion con el algoritmo K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_num = 1\n",
    "n_clusters=2\n",
    "\n",
    "# Aplicamos los clusters para la comparacion\n",
    "datasets = [blobs, no_structure,noisy_circles, noisy_moons]\n",
    "for i_dataset, dataset in enumerate(datasets):\n",
    "    X, y = dataset\n",
    "\n",
    "    # Normalizar datos para un facil selecion de parametros\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Una forma de llegar a tu matris de similitud, generando una matriz de conectividad entre los puntos\n",
    "    connectivity = kneighbors_graph(X, n_neighbors=10)\n",
    "    # conectividad simetrica\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # calculando distancias\n",
    "    distances = euclidean_distances(X)\n",
    "\n",
    "    # instaciando Cluster (K-means y Spectral Clustering)\n",
    "    two_means = cluster.MiniBatchKMeans(n_clusters=n_clusters)\n",
    "    spectral = cluster.SpectralClustering(n_clusters=n_clusters,\n",
    "                                          eigen_solver='arpack',\n",
    "                                          affinity='nearest_neighbors',\n",
    "                                          assign_labels='discretize')\n",
    "    \n",
    "\n",
    "\n",
    "    for algorithm in [two_means, spectral]:\n",
    "        t0 = time.time()\n",
    "        algorithm.fit(X)\n",
    "        t1 = time.time()\n",
    "        if hasattr(algorithm, 'labels_'):\n",
    "            y_pred = algorithm.labels_.astype(np.int)\n",
    "        else:\n",
    "            y_pred = algorithm.predict(X)\n",
    "\n",
    "        # plot\n",
    "        pl.subplot(4, 2, plot_num)\n",
    "        if i_dataset == 0:\n",
    "            pl.title(str(algorithm).split('(')[0], size=18)\n",
    "        pl.scatter(X[:, 0], X[:, 1], color=colors[y_pred].tolist(), s=10)\n",
    "\n",
    "        if hasattr(algorithm, 'cluster_centers_'):\n",
    "            centers = algorithm.cluster_centers_\n",
    "            center_colors = colors[:len(centers)]\n",
    "            pl.scatter(centers[:, 0], centers[:, 1], s=100, c=center_colors)\n",
    "        pl.xlim(-2.5, 2.5)\n",
    "        pl.ylim(-2.5, 2.5)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "        pl.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "                transform=pl.gca().transAxes, size=15,\n",
    "                horizontalalignment='right')\n",
    "        plot_num += 1\n",
    "\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrando Eigen Vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.manifold import SpectralEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir los circulos que seran usados, para usar la funcion espectral para ver la iteracion de los Eigen vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = 100\n",
    "x, y = np.indices((l, l))\n",
    "\n",
    "center1 = (28, 24)\n",
    "center2 = (40, 50)\n",
    "center3 = (67, 58)\n",
    "center4 = (24, 70)\n",
    "\n",
    "radius1, radius2 = 16, 14\n",
    "\n",
    "circle1 = (x - center1[0]) ** 2 + (y - center1[1]) ** 2 < radius1 ** 2\n",
    "circle2 = (x - center2[0]) ** 2 + (y - center2[1]) ** 2 < radius2 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 circles\n",
    "img = circle1 + circle2\n",
    "mask = img.astype(bool)\n",
    "img = img.astype(float)\n",
    "\n",
    "img += 1 + 0.1 * np.random.randn(*img.shape)\n",
    "\n",
    "graph = image.img_to_graph(img, mask=mask)\n",
    "graph.data = np.exp(-graph.data / graph.data.std())\n",
    "\n",
    "se = SpectralEmbedding(n_components=5,affinity='precomputed')\n",
    "\n",
    "Y = se.fit_transform(graph.toarray())\n",
    "\n",
    "for j in range(0,se.n_components):\n",
    "    pl.subplot(1,se.n_components, j+1)\n",
    "    label_im = -np.ones(mask.shape)\n",
    "    label_im[mask] = Y[:,j]\n",
    "    pl.title('Eigen Vector. %i' % (j+1), size=18)\n",
    "    pl.imshow(label_im,cmap=pl.cm.Spectral)\n",
    "pl.show()\n",
    "pl.figure()\n",
    "pl.scatter(Y[:, 1], Y[:, 2], c=Y[:,0], cmap=pl.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicacion de Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.utils.testing import SkipTest\n",
    "from sklearn.utils.fixes import sp_version\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "img2 = Image.open('lena.png')  # Se abre la imagen PNG\n",
    "grises = ImageOps.grayscale(img2)\n",
    "\n",
    "# Para agilizar el procesamiento de la imagen se reduce el tamaño al 50%\n",
    "grises = sp.misc.imresize(grises, 0.50) / 255.\n",
    "\n",
    "# Convertimos la imagen en un grafo con valores de la gradiente en las aristas.\n",
    "graph = image.img_to_graph(grises)\n",
    "\n",
    "# Definimos un parametro beta, mientras mas pequeño sea ese valor la segmentacion es mas independiente\n",
    "beta = 7\n",
    "eps = 1e-6\n",
    "\n",
    "# Usamos la funcion decreciente de la gradiente (exponencial)\n",
    "graph.data = np.exp(-beta * graph.data / graph.data.std()) + eps\n",
    "\n",
    "# Numero de regiones a segmentar\n",
    "N_REGIONS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for assign_labels in ('kmeans', 'discretize'):\n",
    "    t0 = time.time()\n",
    "    labels = spectral_clustering(graph, n_clusters=N_REGIONS,\n",
    "                                 assign_labels=assign_labels, random_state=1)\n",
    "    t1 = time.time()\n",
    "    labels = labels.reshape(grises.shape)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(grises, cmap=plt.cm.gray)\n",
    "    for l in range(N_REGIONS):\n",
    "        plt.contour(labels == l, contours=1,\n",
    "                    colors=[plt.cm.spectral(l / float(N_REGIONS))])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    title = 'Spectral clustering: %s, %.2fs' % (assign_labels, (t1 - t0))\n",
    "    print(title)\n",
    "    plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
